{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "data_dir = \"/home/jack/Desktop/NN/clean/datasets/yelp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(input_file, output_file):\n",
    "    \"\"\"\n",
    "    The function process the data files for Delete & Generate and convert\n",
    "    it for the Delete, Retrieve and Generate training by separating the content\n",
    "    and attributes. It includes all the attribure words.\n",
    "    \n",
    "    Input_file: string : Path of the input file\n",
    "    Output_file: string : Path of the output file \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(input_file) as fp:\n",
    "        data = fp.read().splitlines()\n",
    "    with open (output_file,\"w\") as out_fp:\n",
    "        for x in tqdm(data):\n",
    "            temp = x.split(\"<START>\")\n",
    "            con = temp[0].replace(\"<POS>\",\"\").replace(\"<NEG>\",\"\").replace(\"<CON_START>\",\"\")\n",
    "            sen = temp[1].replace(\"<END>\",\"\")\n",
    "            lt1 = con.split()\n",
    "            lt2 = sen.split()\n",
    "            att_tokens = [z for z in lt2 if z not in lt1]\n",
    "            max_atts = 0\n",
    "            if len(att_tokens) > max_atts:\n",
    "                max_atts = len(att_tokens)\n",
    "            att_words = \" \".join(att_tokens)\n",
    "            out_str = \"<ATTR_WORDS> \" + att_words + \" <CON_START> \" + con.strip() + \" <START> \" + sen.strip() + \" <END>\" + \"\\n\"\n",
    "            out_fp.write(out_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_v1(input_file, output_file, test = False):\n",
    "    \"\"\"\n",
    "    The function process the data files for Delete & Generate and convert\n",
    "    it for the Delete, Retrieve and Generate training by separating the content\n",
    "    and attributes. \n",
    "    It randomly picks 70% of the attributes only to make the generation\n",
    "    more realistic instead of just filling the blanks, which helps while generating\n",
    "    sentences for test cases.\n",
    "    \n",
    "    Input_file: string : Path of the input file\n",
    "    Output_file: string : Path of the output file \n",
    "    \"\"\"\n",
    "    with open(input_file) as fp:\n",
    "        data = fp.read().splitlines()\n",
    "    with open (output_file,\"w\") as out_fp:\n",
    "        for x in tqdm(data):\n",
    "            temp = x.split(\"<START>\")\n",
    "            con = temp[0].replace(\"<POS>\",\"\").replace(\"<NEG>\",\"\").replace(\"<CON_START>\",\"\")\n",
    "            sen = temp[1].replace(\"<END>\",\"\")\n",
    "            lt1 = con.split()\n",
    "            org_lt1 = copy.deepcopy(lt1)\n",
    "            lt2 = sen.split()\n",
    "           \n",
    "            \n",
    "            att_words = [z for z in lt2 if z not in lt1]\n",
    "            att_words = list(reversed(sorted(att_words, key=len)))\n",
    "            index_att = []\n",
    "\n",
    "            # Don't put special char in attribute words. Reduce att -> reduce confusion\n",
    "            my_att = []\n",
    "\n",
    "            special_characters =  \"!@#$%^&*()-+?_=<>/\\'\\'\"\n",
    "            for index, word  in enumerate(lt2) :\n",
    "                if word in special_characters:\n",
    "                    continue\n",
    "                if word in lt1:\n",
    "                    continue\n",
    "                if any(c in special_characters for c in word) and len(word) < 3:\n",
    "                    continue\n",
    "                if \"-\" in word:\n",
    "                    splitted_words = word.split(\"-\")\n",
    "                    if splitted_words[0] in lt1 and splitted_words[1] in lt1:\n",
    "                        continue\n",
    "                if any(c in special_characters for c in word) and len(word) < 4:\n",
    "                    splitted_words = word.split(\"\\'\")\n",
    "                    if len(splitted_words)>0 and splitted_words[0] in lt1 and splitted_words[1] in lt1:\n",
    "                        continue\n",
    "                # Attribute found\n",
    "                my_att.append(word)\n",
    "                # Remember index\n",
    "                index_att.append(index)\n",
    "            \n",
    "\n",
    "            att_words = my_att\n",
    "\n",
    "            set_replace_tokens(lt1, lt2, att_words, index_att)\n",
    "            \n",
    "            # Remove special chars first\n",
    "            if len(att_words) > 2:\n",
    "                for index,word in enumerate(att_words):\n",
    "                    if any(c in special_characters for c in word) and len(att_words) > 2:\n",
    "                        del att_words[index]\n",
    "\n",
    "\n",
    "            if len(att_words) > 2:\n",
    "                indx = np.array(list(range(len(att_words))))\n",
    "                # Pref delete short words\n",
    "                #print(\"attr b4\", att_words)\n",
    "                att_words = \" \".join([att_words[indx[k]] for k in range(int(0.7 * len(att_words)))])\n",
    "                #print(\"attr after\", att_words)\n",
    "\n",
    "                #np.random.shuffle(indx)\n",
    "            else: # If attributes less than 2 then keep all the attributes\n",
    "                att_words = \" \".join(att_words)\n",
    "            if(test):\n",
    "                out_str = \"<ATTR_WORDS> \" + att_words + \" <CON_START> \" +  \" \".join(lt1).strip() + \" <START> \" + \"\\n\"\n",
    "            else:\n",
    "                out_str = \"<ATTR_WORDS> \" + att_words + \" <CON_START> \" +  \" \".join(lt1).strip() + \" <START> \" + sen.strip() + \" <END>\"  + \"\\n\"\n",
    "            out_fp.write(out_str)\n",
    "\n",
    "def set_replace_tokens(content_list, full_list, att_list, index_att_list, second_try = False):\n",
    "    street_index = 0\n",
    "    last_replace_index = None\n",
    "    insert_index = None\n",
    "    for index, replace_index in enumerate(index_att_list):\n",
    "        # Catch street \n",
    "        if last_replace_index == replace_index - 1:\n",
    "            content_list.insert(replace_index, \"<REPLACE>\")\n",
    "            last_replace_index = replace_index\n",
    "            continue\n",
    "\n",
    "        last_replace_index = replace_index\n",
    "        # Catch first street if starts with 0\n",
    "        if replace_index == street_index:\n",
    "            street_index += 1\n",
    "            content_list.insert(replace_index, \"<REPLACE>\")\n",
    "            continue\n",
    "\n",
    "        left_matches = []\n",
    "        right_matches = []\n",
    "        left_word_query = None\n",
    "        right_word_query = None\n",
    "        \n",
    "        if replace_index-1 >= 0:\n",
    "            left_word_query = full_list[replace_index-1]\n",
    "            left_matches = [(index,x) for index,x in enumerate(content_list) if x == left_word_query]\n",
    "\n",
    "        if replace_index+1 < len(full_list):\n",
    "            right_word_query = full_list[replace_index+1]\n",
    "            right_matches = [(index,x) for index,x in enumerate(content_list) if x == right_word_query]\n",
    "\n",
    "        if len(left_matches) == 1:\n",
    "            insert_index = left_matches[0][0]+1\n",
    "            content_list.insert(insert_index, \"<REPLACE>\")\n",
    "            continue\n",
    "        \n",
    "        if len(right_matches) == 1:\n",
    "            insert_index = right_matches[0][0]\n",
    "            content_list.insert(insert_index, \"<REPLACE>\")            \n",
    "            continue\n",
    "\n",
    "\n",
    "        left_concat_matches = []\n",
    "        right_concat_matches = []\n",
    "        if left_word_query != None:\n",
    "            left_concat_matches = [(index,x) for index,x in enumerate(content_list) if index-1 > -1 and content_list[index-1]+content_list[index] == left_word_query]\n",
    "        if right_word_query != None:\n",
    "            right_concat_matches = [(index,x) for index,x in enumerate(content_list) if index+1 < len(content_list) and content_list[index]+content_list[index+1] == right_word_query]\n",
    "        \n",
    "        if len(left_concat_matches) == 1: \n",
    "            insert_index = left_concat_matches[0][0]+1\n",
    "            content_list.insert(insert_index, \"<REPLACE>\")\n",
    "            continue\n",
    "\n",
    "        if len(right_concat_matches) == 1: \n",
    "            insert_index = right_concat_matches[0][0]\n",
    "            content_list.insert(insert_index, \"<REPLACE>\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        left_shifted_match = []\n",
    "        right_shifted_matches = []\n",
    "        if replace_index-2 >= 0:\n",
    "            left_word_query_shift = full_list[replace_index-2]\n",
    "            left_shifted_match = [(index,x) for index,x in enumerate(content_list) if index-1 > -1 and content_list[index-1] == left_word_query_shift]\n",
    "        if replace_index+2 < len(full_list):\n",
    "            right_word_query_shift = full_list[replace_index+2]\n",
    "            right_shifted_matches = [(index,x) for index,x in enumerate(content_list) if index+1 < len(content_list) and content_list[index+1] == right_word_query_shift]\n",
    "\n",
    "        if len(left_shifted_match) == 1: \n",
    "            insert_index = left_shifted_match[0][0]+1\n",
    "            content_list.insert(insert_index, \"<REPLACE>\")\n",
    "            continue\n",
    "\n",
    "        if len(right_shifted_matches) == 1: \n",
    "            insert_index = right_shifted_matches[0][0]\n",
    "            content_list.insert(insert_index, \"<REPLACE>\")\n",
    "            continue\n",
    "\n",
    "        if len(left_matches) == 0 and len(right_matches) == 0:\n",
    "            print(\"NONE\", index)\n",
    "            print(att_list)\n",
    "            print(index_att_list)\n",
    "            print(content_list)\n",
    "            print(full_list)\n",
    "\n",
    "def next_is_street(index_att_list, current_index):\n",
    "    if len(index_att_list) > current_index+1 and  index_att_list[current_index] + 1 == index_att_list[current_index+1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_street_length(index_att_list, current_index):\n",
    "    counter = 0\n",
    "    while len(index_att_list) > current_index+1 and  index_att_list[current_index] + 1 == index_att_list[current_index+1]:\n",
    "        counter += 1\n",
    "        current_index += 1\n",
    "    return counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 51666.08it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 54584.90it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 48445.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test changes here first\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test.txt\")\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test_1.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test_1.txt\")\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test_0.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test_0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Merge files'''\n",
    "# Create sentiment_train file before run!\n",
    "# Create sentiment_test file before run!\n",
    "# Create sentiment_dev file before run!\n",
    "\n",
    "filenames = [data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train_1.txt\", data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train_0.txt\"]\n",
    "with open(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train.txt\", 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "\n",
    "\n",
    "filenames = [data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test_1.txt\", data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test_0.txt\"]\n",
    "with open(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test.txt\", 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "\n",
    "filenames = [data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev_1.txt\", data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev_0.txt\"]\n",
    "with open(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev.txt\", 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 443259/443259 [00:01<00:00, 314534.16it/s]\n",
      "100%|██████████| 266041/266041 [00:00<00:00, 344643.63it/s]\n",
      "100%|██████████| 177218/177218 [00:00<00:00, 316493.76it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_train_all_attrs.txt\")\n",
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train_1.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_train_1_all_attrs.txt\")\n",
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train_0.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_train_0_all_attrs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 142784.82it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 265529.50it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 269660.79it/s]\n"
     ]
    }
   ],
   "source": [
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test_all_attrs.txt\")\n",
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test_1.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test_1_all_attrs.txt\")\n",
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test_0.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test_0_all_attrs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_dev_all_attrs.txt\")\n",
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev_0.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_dev_1_all_attrs.txt\")\n",
    "process_file(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev_1.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_dev_0_all_attrs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_train.txt\")\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train_1.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_train_1.txt\")\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_train_0.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_train_0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 56367.48it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 71094.72it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 66485.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test changes here first\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test.txt\")\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test_1.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test_1.txt\")\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_test_0.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_test_0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_dev.txt\", test=True)\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev_0.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_dev_1.txt\", test=True)\n",
    "process_file_v1(data_dir+\"/processed_files_with_bert_with_best_head/sentiment_dev_1.txt\",data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/sentiment_dev_0.txt\", test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path) as fp:\n",
    "        data = fp.read().splitlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<POS> <CON_START> so basically down . <START>so basically tasted watered down .\n"
     ]
    }
   ],
   "source": [
    "# Process real ref with antonmys attributes - Do NOT execute\n",
    "\n",
    "ref_original_path_0 = data_dir+\"/reference_0_org.txt\"\n",
    "ref_original_path_1 = data_dir+\"/reference_1_org.txt\"\n",
    "\n",
    "ref_0_data = read_file(ref_original_path_0)\n",
    "ref_1_data = read_file(ref_original_path_1)\n",
    "\n",
    "original_data_0 = [x.split(\"\t\")[0] for x in ref_0_data]\n",
    "original_data_1 = [x.split(\"\t\")[0] for x in ref_1_data]\n",
    "\n",
    "ref_content_path_0 = data_dir+\"/processed_files_with_bert_with_best_head/reference_0.txt\"\n",
    "ref_content_path_1 = data_dir+\"/processed_files_with_bert_with_best_head/reference_1.txt\"\n",
    "\n",
    "original_content_data_0 = read_file(ref_content_path_0)\n",
    "original_content_data_1 = read_file(ref_content_path_1)\n",
    "\n",
    "\n",
    "output_0_content_org = data_dir+\"/processed_files_with_bert_with_best_head/reference_content_org_0.txt\"\n",
    "output_1_content_org = data_dir+\"/processed_files_with_bert_with_best_head/reference_content_org_1.txt\"\n",
    "\n",
    "print(original_content_data_0[2]+original_data_0[2])\n",
    "\n",
    "with open(output_0_content_org, 'w') as outfile:\n",
    "    for index, content in enumerate(original_content_data_0):\n",
    "        outfile.write(content+original_data_0[index]+\"\\n\")\n",
    "\n",
    "with open(output_1_content_org, 'w') as outfile:\n",
    "    for index, content in enumerate(original_content_data_1):\n",
    "            outfile.write(content+original_data_1[index]+\"\\n\")\n",
    "\n",
    "#content_with_att_0 = process_file_v1()\n",
    "\n",
    "ref_out_path_0 = data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/reference_0.txt\"\n",
    "ref_out_path_1 = data_dir+\"/processed_files_with_bert_with_best_head/delete_retrieve_edit_model/reference_1.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 29555.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr b4 ['said', 'disappeared', 'minutes']\n",
      "attr after said disappeared\n",
      "attr b4 ['terrible', 'very', 'good']\n",
      "attr after terrible very\n",
      "attr b4 ['owner', 'heard', 'do']\n",
      "attr after owner heard\n",
      "attr b4 ['sit', 'slow', 'lazy']\n",
      "attr after sit slow\n",
      "attr b4 ['no', 'sorry', 'everything']\n",
      "attr after no sorry\n",
      "attr b4 ['said', 'sit', 'table']\n",
      "attr after said sit\n",
      "attr b4 ['empty', 'no', 'store']\n",
      "attr after empty no\n",
      "attr b4 ['staffed', 'primarily', 'teenagers']\n",
      "attr after staffed primarily\n",
      "attr b4 ['blue', 'cheese', 'best']\n",
      "attr after blue cheese\n",
      "attr b4 ['pad', 'tasted', 'noodles']\n",
      "attr after pad tasted\n",
      "attr b4 ['complained', 'polite', 'walked']\n",
      "attr after complained polite\n",
      "attr b4 ['anyway', 'got', 'coffee']\n",
      "attr after anyway got\n",
      "attr b4 ['just', 'delivery', 'wasted']\n",
      "attr after just delivery\n",
      "attr b4 [\"n't\", 'let', 'me']\n",
      "attr after n't let\n",
      "attr b4 ['me', 'lied', 'bs']\n",
      "attr after me lied\n",
      "attr b4 ['tried', 'advantage', 'am']\n",
      "attr after tried advantage\n",
      "attr b4 [\"'ve\", 'sent', 'guests', 'absolutely']\n",
      "attr after 've sent\n",
      "attr b4 ['really', 'need', 'attitude']\n",
      "attr after really need\n",
      "attr b4 ['``', 'cold', 'watery']\n",
      "attr after `` cold\n",
      "attr b4 ['...', 'yes', 'sounded', 'indian']\n",
      "attr after ... yes\n",
      "attr b4 ['wo', 'better', 'selection']\n",
      "attr after wo better\n",
      "attr b4 ['hot', 'received', 'spice']\n",
      "attr after hot received\n",
      "attr b4 ['meal', 'said', '``', \"'ll\"]\n",
      "attr after meal said\n",
      "attr b4 ['food', 'ok', 'worst']\n",
      "attr after food ok\n",
      "attr b4 ['curious', 'product', 'walked']\n",
      "attr after curious product\n",
      "attr b4 ['safeway', 'lost', 'fresh']\n",
      "attr after safeway lost\n",
      "attr b4 ['bad', 'would', 'go']\n",
      "attr after bad would\n",
      "attr b4 [\"'ll\", 'zero', 'bite']\n",
      "attr after 'll zero\n",
      "attr b4 ['do', 'go', 'crap']\n",
      "attr after do go\n",
      "attr b4 ['stopped', 'soda', 'hobby']\n",
      "attr after stopped soda\n",
      "attr b4 ['dish', 'could', 'barely']\n",
      "attr after dish could\n",
      "attr b4 ['looks', 'blended', 'chicken']\n",
      "attr after looks blended\n",
      "attr b4 ['happy', 'hours', 'beers']\n",
      "attr after happy hours\n",
      "attr b4 ['executive', 'walk', 'not']\n",
      "attr after executive walk\n",
      "attr b4 ['visitor', 'limited', 'play']\n",
      "attr after visitor limited\n",
      "attr b4 ['``', 'dessert', 'even']\n",
      "attr after `` dessert\n",
      "attr b4 ['disgusted', 'could', 'day']\n",
      "attr after disgusted could\n",
      "attr b4 ['love', '...', 'horrible']\n",
      "attr after love ...\n",
      "attr b4 ['needless', 'mexican', 'food']\n",
      "attr after needless mexican\n",
      "attr b4 ['let', 'opinion', 'site']\n",
      "attr after let opinion\n",
      "attr b4 [\"'ve\", 'tried', 'pancakes']\n",
      "attr after 've tried\n",
      "attr b4 [\"'ve\", 'never', 'worse']\n",
      "attr after 've never\n",
      "attr b4 ['drunk', 'could', 'pizza']\n",
      "attr after drunk could\n",
      "attr b4 ['as', 'been', 'going']\n",
      "attr after as been\n",
      "attr b4 ['got', 'seated', 'chose']\n",
      "attr after got seated\n",
      "attr b4 ['no', 'no', 'condition']\n",
      "attr after no no\n",
      "attr b4 ['so', 'do', 'money']\n",
      "attr after so do\n",
      "attr b4 ['badly', 'consistency', 'canned']\n",
      "attr after badly consistency\n",
      "attr b4 ['did', 'full', 'water']\n",
      "attr after did full\n",
      "attr b4 ['food', 'very', 'get']\n",
      "attr after food very\n",
      "attr b4 ['just', 'went', 'rear']\n",
      "attr after just went\n",
      "attr b4 ['message', 'never', 'me']\n",
      "attr after message never\n",
      "attr b4 ['food', 'worse', 'find']\n",
      "attr after food worse\n",
      "attr b4 ['real', 'hard', 'refused']\n",
      "attr after real hard\n",
      "attr b4 ['comes', 'pounds', 'open']\n",
      "attr after comes pounds\n",
      "attr b4 ['wanted', 'became', 'disappointment']\n",
      "attr after wanted became\n",
      "attr b4 ['did', 'can', 'tips']\n",
      "attr after did can\n",
      "attr b4 ['so', 'sad', 'am']\n",
      "attr after so sad\n",
      "attr b4 ['worst', 'neighborhood', 'market']\n",
      "attr after worst neighborhood\n",
      "attr b4 ['just', 'ordering', \"'re\", 'seated']\n",
      "attr after just ordering\n",
      "attr b4 ['lost', 'good', 'food']\n",
      "attr after lost good\n",
      "attr b4 ['found', 'dead', 'mouse']\n",
      "attr after found dead\n",
      "attr b4 ['no', 'sausage', 'bacon']\n",
      "attr after no sausage\n",
      "attr b4 ['failed', 'apologize', 'horrific']\n",
      "attr after failed apologize\n",
      "attr b4 ['did', 'answer', 'hung']\n",
      "attr after did answer\n",
      "attr b4 ['south', 'facing', \"'re\"]\n",
      "attr after south facing\n",
      "attr b4 ['dude', 'did', 'computer']\n",
      "attr after dude did\n",
      "attr b4 ['lost', 'good', 'local']\n",
      "attr after lost good\n",
      "attr b4 ['food', 'too', 'cooked']\n",
      "attr after food too\n",
      "attr b4 ['food', 'cold', 'frozen']\n",
      "attr after food cold\n",
      "attr b4 ['food', \"n't\", 'great']\n",
      "attr after food n't\n",
      "attr b4 ['exhibit', 'c', 'services']\n",
      "attr after exhibit c\n",
      "attr b4 ['shows', 'saturday', \"n't\"]\n",
      "attr after shows saturday\n",
      "attr b4 ['received', 'star', 'provide']\n",
      "attr after received star\n",
      "attr b4 ['food', 'edible', 'horrible']\n",
      "attr after food edible\n",
      "attr b4 ['however', 'tech', 'said']\n",
      "attr after however tech\n",
      "attr b4 ['bay', 'disappointment', 'priced']\n",
      "attr after bay disappointment\n",
      "attr b4 ['ordered', 'chicken', 'ordered']\n",
      "attr after ordered chicken\n",
      "attr b4 ['ordered', 'garlic', 'vegetables']\n",
      "attr after ordered garlic\n",
      "attr b4 ['um', '...', 'just', 'finance']\n",
      "attr after um ...\n",
      "attr b4 ['tasted', 'really', 'could']\n",
      "attr after tasted really\n",
      "attr b4 ['alright', 'maybe', 'should']\n",
      "attr after alright maybe\n",
      "attr b4 ['lastly', 'brownie', 'desert', '...']\n",
      "attr after lastly brownie\n",
      "attr b4 ['broken', 'thing', 'do']\n",
      "attr after broken thing\n",
      "attr b4 [\"'ve\", 'long', 'established', 'restaurant']\n",
      "attr after 've long\n",
      "attr b4 ['looked', 'half', 'empty']\n",
      "attr after looked half\n",
      "attr b4 ['gave', 'minutes', 'left']\n",
      "attr after gave minutes\n",
      "attr b4 ['wendy', 'know', 'cheap']\n",
      "attr after wendy know\n",
      "attr b4 [\"'ve\", 'eaten', 'here', 'bad']\n",
      "attr after 've eaten\n",
      "attr b4 ['always', 'takes', 'too', \"'re\"]\n",
      "attr after always takes\n",
      "attr b4 ['however', 'paid', 'nails']\n",
      "attr after however paid\n",
      "attr b4 ['enjoy', 'place', 'very']\n",
      "attr after enjoy place\n",
      "attr b4 ['employees', 'apologized', 'sincere']\n",
      "attr after employees apologized\n",
      "attr b4 ['long', 'did', 'me']\n",
      "attr after long did\n",
      "attr b4 ['recommend', 'buying', 'camping']\n",
      "attr after recommend buying\n",
      "attr b4 ['charged', 'me', 'parts']\n",
      "attr after charged me\n",
      "attr b4 ['travel', 'stay', 'hotel']\n",
      "attr after travel stay\n",
      "attr b4 ['would', 'food', 'cold']\n",
      "attr after would food\n",
      "attr b4 ['am', 'good', 'cook']\n",
      "attr after am good\n",
      "attr b4 ['difficult', 'actually', 'good']\n",
      "attr after difficult actually\n",
      "attr b4 ['terrible', 'employees', 'act']\n",
      "attr after terrible employees\n",
      "attr b4 [\"'ll\", 'looking', 'salon']\n",
      "attr after 'll looking\n",
      "attr b4 ['can', 'pay', 'shop']\n",
      "attr after can pay\n",
      "attr b4 ['said', 'eggs', 'cold']\n",
      "attr after said eggs\n",
      "attr b4 ['food', ':', 'horrible']\n",
      "attr after food :\n",
      "attr b4 ['worst', 'food', \"'ve\"]\n",
      "attr after worst food\n",
      "attr b4 ['place', 'old', 'urine']\n",
      "attr after place old\n",
      "attr b4 ['20-30', 'capacity', 'pool']\n",
      "attr after 20-30 capacity\n",
      "attr b4 ['found', 'place', 'bad']\n",
      "attr after found place\n",
      "attr b4 ['hours', 'life', 'can']\n",
      "attr after hours life\n",
      "attr b4 ['dropped', 'off', 'shoes']\n",
      "attr after dropped off\n",
      "attr b4 ['pace', 'bad', 'waits']\n",
      "attr after pace bad\n",
      "attr b4 ['did', 'offer', 'me']\n",
      "attr after did offer\n",
      "attr b4 ['crisp', 'tiny', 'crisp']\n",
      "attr after crisp tiny\n",
      "attr b4 ['said', 'certificate', 'good']\n",
      "attr after said certificate\n",
      "attr b4 [':', 'no', 'just']\n",
      "attr after : no\n",
      "attr b4 ['however', 'turned', 'nothing']\n",
      "attr after however turned\n",
      "attr b4 ['went', 'adjustment', 'incorrect']\n",
      "attr after went adjustment\n",
      "attr b4 ['horrible', 'sadly', 'would']\n",
      "attr after horrible sadly\n",
      "attr b4 ['contacted', 'store', 'leaving']\n",
      "attr after contacted store\n",
      "attr b4 ['ordered', 'blackened', 'chicken']\n",
      "attr after ordered blackened\n",
      "attr b4 ['not', 'terribly', 'hot']\n",
      "attr after not terribly\n",
      "attr b4 ['did', 'me', 'copy']\n",
      "attr after did me\n",
      "attr b4 ['emailed', 'let', 'apparently']\n",
      "attr after emailed let\n",
      "attr b4 ['could', 'pressure', 'though']\n",
      "attr after could pressure\n",
      "attr b4 ['absolutely', 'terrible', 'place']\n",
      "attr after absolutely terrible\n",
      "attr b4 ['ate', 'kicked', 'not']\n",
      "attr after ate kicked\n",
      "attr b4 ['simply', 'not', 'good']\n",
      "attr after simply not\n",
      "attr b4 ['yes', 'portions', 'size']\n",
      "attr after yes portions\n",
      "attr b4 [\"'ll\", 'holding', 'breath']\n",
      "attr after 'll holding\n",
      "attr b4 ['management', 'does', \"n't\"]\n",
      "attr after management does\n",
      "attr b4 ['no', 'restaurants', 'closing']\n",
      "attr after no restaurants\n",
      "attr b4 ['charge', 'purchase', 'bagels']\n",
      "attr after charge purchase\n",
      "attr b4 ['woman', 'should', 'az']\n",
      "attr after woman should\n",
      "attr b4 ['average', 'could', 'poor']\n",
      "attr after average could\n",
      "attr b4 ['walk', 'up', 'bar']\n",
      "attr after walk up\n",
      "attr b4 ['cold', 'quite', 'awful']\n",
      "attr after cold quite\n",
      "attr b4 ['embarrassing', 'involved', 'do']\n",
      "attr after embarrassing involved\n",
      "attr b4 ['so', 'ordered', 'tires']\n",
      "attr after so ordered\n",
      "attr b4 ['hopefully', 'do', 'bugs']\n",
      "attr after hopefully do\n",
      "attr b4 ['beer', 'food', 'desirable']\n",
      "attr after beer food\n",
      "attr b4 ['false', 'advertising', 'go']\n",
      "attr after false advertising\n",
      "attr b4 ['food', 'bad', 'terrible']\n",
      "attr after food bad\n",
      "attr b4 ['crab', 'salt', 'no']\n",
      "attr after crab salt\n",
      "attr b4 ['just', 'manager', 'complain']\n",
      "attr after just manager\n",
      "attr b4 ['geez', 'need', 'source', '...']\n",
      "attr after geez need\n",
      "attr b4 ['does', 'just', 'walks']\n",
      "attr after does just\n",
      "attr b4 ['ordered', 'short', 'over-cooked']\n",
      "attr after ordered short\n",
      "attr b4 ['did', 'good', 'at']\n",
      "attr after did good\n",
      "attr b4 ['acknowledged', 'went', 'back']\n",
      "attr after acknowledged went\n",
      "attr b4 ['dog', 'wife', 'dog']\n",
      "attr after dog wife\n",
      "attr b4 ['fault', 'not', 'guess']\n",
      "attr after fault not\n",
      "attr b4 ['reason', 'wo', 'return']\n",
      "attr after reason wo\n",
      "attr b4 [\"n't\", 'coworker', \"'ve\", 'walked']\n",
      "attr after n't coworker\n",
      "attr b4 ['went', 'sunday', 'celebrate']\n",
      "attr after went sunday\n",
      "attr b4 [\"'ve\", 'messed', 'spice']\n",
      "attr after 've messed\n",
      "attr b4 ['game', 'room', 'waste']\n",
      "attr after game room\n",
      "attr b4 ['told', 'good', 'feedback']\n",
      "attr after told good\n",
      "attr b4 ['so', 'not', 'just']\n",
      "attr after so not\n",
      "attr b4 ['told', 'forget', 'did']\n",
      "attr after told forget\n",
      "attr b4 ['oh', '...', 'right']\n",
      "attr after oh ...\n",
      "attr b4 ['uneven', 'falling', 'paid']\n",
      "attr after uneven falling\n",
      "attr b4 ['did', 'anything', 'day']\n",
      "attr after did anything\n",
      "attr b4 ['not', 'thin', 'taste']\n",
      "attr after not thin\n",
      "attr b4 ['gave', 'me', 'soup']\n",
      "attr after gave me\n",
      "attr b4 ['not', 'fan', 'huge']\n",
      "attr after not fan\n",
      "attr b4 ['great', 'horrible', 'rude']\n",
      "attr after great horrible\n",
      "attr b4 ['dish', 'sauce', 'secret']\n",
      "attr after dish sauce\n",
      "attr b4 ['go', 'interested', 'good']\n",
      "attr after go interested\n",
      "attr b4 ['safe', 'going', 'locations']\n",
      "attr after safe going\n",
      "attr b4 ['bar', 'skip', 'restaurant']\n",
      "attr after bar skip\n",
      "attr b4 ['let', 'place', 'busy']\n",
      "attr after let place\n",
      "attr b4 ['birthday', 'ruined', 'special']\n",
      "attr after birthday ruined\n",
      "attr b4 ['included', 'credit', 'midnight']\n",
      "attr after included credit\n",
      "attr b4 ['item', 'able', 'eat']\n",
      "attr after item able\n",
      "attr b4 ['really', 'do', 'good']\n",
      "attr after really do\n",
      "attr b4 ['did', \"n't\", 'feel']\n",
      "attr after did n't\n",
      "attr b4 ['door', 'would', 'open']\n",
      "attr after door would\n",
      "attr b4 ['very', 'rushed', 'good']\n",
      "attr after very rushed\n",
      "attr b4 ['then', 'rude', 'overwhelmed']\n",
      "attr after then rude\n",
      "attr b4 ['may', 'just', 'pictures']\n",
      "attr after may just\n",
      "attr b4 ['sadly', 'able', 'place']\n",
      "attr after sadly able\n",
      "attr b4 ['looked', 'chicken', 'lacking']\n",
      "attr after looked chicken\n",
      "attr b4 ['burnt', 'noodles', 'floor']\n",
      "attr after burnt noodles\n",
      "attr b4 ['do', 'screwed', 'short']\n",
      "attr after do screwed\n",
      "attr b4 ['wait', 'said', 'unsure']\n",
      "attr after wait said\n",
      "attr b4 ['could', 'not', 'bring']\n",
      "attr after could not\n",
      "attr b4 ['went', 'extremely', 'slow']\n",
      "attr after went extremely\n",
      "attr b4 ['manager', 'fire', 'spot']\n",
      "attr after manager fire\n",
      "attr b4 ['food', 'low', 'thrown']\n",
      "attr after food low\n",
      "attr b4 ['um', 'does', 'replacing']\n",
      "attr after um does\n",
      "attr b4 ['needless', 'returning', 'place']\n",
      "attr after needless returning\n",
      "attr b4 ['firstly', 'fees', 'generally']\n",
      "attr after firstly fees\n",
      "attr b4 ['built', 'sink', 'not']\n",
      "attr after built sink\n",
      "attr b4 ['university', 'bad', 'apache']\n",
      "attr after university bad\n",
      "attr b4 ['refused', 'pictures', 'quality']\n",
      "attr after refused pictures\n",
      "attr b4 ['perhaps', 'bread', 'should']\n",
      "attr after perhaps bread\n",
      "attr b4 ['simply', 'superior', 'go']\n",
      "attr after simply superior\n",
      "attr b4 ['took', 'fitted', 'button']\n",
      "attr after took fitted\n",
      "attr b4 ['person', 'meal', 'meal']\n",
      "attr after person meal\n",
      "attr b4 ['rush', 'rush', 'customers']\n",
      "attr after rush rush\n",
      "attr b4 ['called', '6:30', 'got', 'brush']\n",
      "attr after called 6:30\n",
      "attr b4 [\"'re\", 'fight', 'breaks']\n",
      "attr after 're fight\n",
      "attr b4 ['only', 'scorpions', \"'ve\", 'dead']\n",
      "attr after only scorpions\n",
      "attr b4 ['did', \"n't\", 'care']\n",
      "attr after did n't\n",
      "attr b4 ['so', 'eat', 'sitting']\n",
      "attr after so eat\n",
      "attr b4 ['location', 'super', 'really']\n",
      "attr after location super\n",
      "attr b4 ['guess', 'starbucks', 'good']\n",
      "attr after guess starbucks\n",
      "attr b4 ['women', 'met', 'elements']\n",
      "attr after women met\n",
      "attr b4 ['``', 'no', 'tournament']\n",
      "attr after `` no\n",
      "attr b4 ['picked', 'order', 'price']\n",
      "attr after picked order\n",
      "attr b4 ['do', 'stock', 'parts']\n",
      "attr after do stock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 46999.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr b4 ['small', 'make', 'right']\n",
      "attr after small make\n",
      "attr b4 ['actually', 'can', 'wait']\n",
      "attr after actually can\n",
      "attr b4 ['friendly', 'delicious', 'authentic']\n",
      "attr after friendly delicious\n",
      "attr b4 [\"'ll\", 'why', 'get']\n",
      "attr after 'll why\n",
      "attr b4 ['variety', 'makes', 'good']\n",
      "attr after variety makes\n",
      "attr b4 ['professional', 'found', 'right']\n",
      "attr after professional found\n",
      "attr b4 ['important', 'thing', 'food']\n",
      "attr after important thing\n",
      "attr b4 ['good', 'impressed', 'quality']\n",
      "attr after good impressed\n",
      "attr b4 ['great', 'nice', 'steal']\n",
      "attr after great nice\n",
      "attr b4 ['still', 'comes', 'right']\n",
      "attr after still comes\n",
      "attr b4 ['love', 'location', 'right']\n",
      "attr after love location\n",
      "attr b4 ['happy', 'definitely', 'services']\n",
      "attr after happy definitely\n",
      "attr b4 ['seems', 'pretty', 'high']\n",
      "attr after seems pretty\n",
      "attr b4 ['great', 'grab', 'meal']\n",
      "attr after great grab\n",
      "attr b4 ['reasonably', 'great', 'organic']\n",
      "attr after reasonably great\n",
      "attr b4 ['first', 'knew', 'new']\n",
      "attr after first knew\n",
      "attr b4 ['certainly', 'good', 'event']\n",
      "attr after certainly good\n",
      "attr b4 ['place', 'making', 'great']\n",
      "attr after place making\n",
      "attr b4 ['helped', 'friendly', 'travel']\n",
      "attr after helped friendly\n",
      "attr b4 ['best', 'enjoyed', 'excellent']\n",
      "attr after best enjoyed\n",
      "attr b4 ['went', 'eight', 'great']\n",
      "attr after went eight\n",
      "attr b4 ['thanks', 'special', 'event']\n",
      "attr after thanks special\n",
      "attr b4 ['big', 'fairly', 'clean']\n",
      "attr after big fairly\n",
      "attr b4 ['uses', 'looks', 'great']\n",
      "attr after uses looks\n",
      "attr b4 ['awesome', 'right', 'heart']\n",
      "attr after awesome right\n",
      "attr b4 ['sit', 'best', 'place']\n",
      "attr after sit best\n",
      "attr b4 ['dropped', 'rental', 'location']\n",
      "attr after dropped rental\n",
      "attr b4 ['adds', 'touch', 'amazing']\n",
      "attr after adds touch\n",
      "attr b4 ['gave', 'new', 'transformed']\n",
      "attr after gave new\n",
      "attr b4 ['crab', 'rule', 'spicy']\n",
      "attr after crab rule\n",
      "attr b4 ['gotten', 'dresses', 'steal']\n",
      "attr after gotten dresses\n",
      "attr b4 ['around', 'great', 'grab']\n",
      "attr after around great\n",
      "attr b4 ['chocolate', 'cake', 'best', \"'ve\"]\n",
      "attr after chocolate cake\n",
      "attr b4 ['nice', 'retail', 'typical']\n",
      "attr after nice retail\n",
      "attr b4 ['loved', 'day', 'ca']\n",
      "attr after loved day\n",
      "attr b4 [\"'re\", 'young', 'sports', 'place']\n",
      "attr after 're young\n",
      "attr b4 ['favorite', 'places', 'great']\n",
      "attr after favorite places\n",
      "attr b4 ['loved', 'ranch', 'really']\n",
      "attr after loved ranch\n",
      "attr b4 ['inexpensive', 'make', 'fun']\n",
      "attr after inexpensive make\n",
      "attr b4 ['made', 'feel', 'extended']\n",
      "attr after made feel\n",
      "attr b4 ['simple', 'cut', 'color']\n",
      "attr after simple cut\n",
      "attr b4 ['nothing', 'happy', 'sent']\n",
      "attr after nothing happy\n",
      "attr b4 [\"'ve\", 'ordered', 'here', 'great']\n",
      "attr after 've ordered\n",
      "attr b4 ['pleasantly', 'surprised', 'brought']\n",
      "attr after pleasantly surprised\n",
      "attr b4 ['reccomend', 'spicy', 'lovers']\n",
      "attr after reccomend spicy\n",
      "attr b4 ['stopped', 'nice', 'good']\n",
      "attr after stopped nice\n",
      "attr b4 ['love', 'happy', 'incredibly']\n",
      "attr after love happy\n",
      "attr b4 ['money', 'enjoy', 'amazing']\n",
      "attr after money enjoy\n",
      "attr b4 ['nice', 'good', 'good']\n",
      "attr after nice good\n",
      "attr b4 ['good', 'rather', 'authentic']\n",
      "attr after good rather\n",
      "attr b4 ['recommend', 'dentistry', 'old']\n",
      "attr after recommend dentistry\n",
      "attr b4 ['upgrade', 'mothers', 'ring']\n",
      "attr after upgrade mothers\n",
      "attr b4 ['salsa', 'fantastic', 'hotter']\n",
      "attr after salsa fantastic\n",
      "attr b4 ['here', 'best', 'decision']\n",
      "attr after here best\n",
      "attr b4 ['great', 'greasy', 'fluffy']\n",
      "attr after great greasy\n",
      "attr b4 ['consistently', 'amazing', 'place']\n",
      "attr after consistently amazing\n",
      "attr b4 ['nothing', 'excellent', 'customer']\n",
      "attr after nothing excellent\n",
      "attr b4 ['super', 'friendly', 'quick']\n",
      "attr after super friendly\n",
      "attr b4 ['great', 'continued', 'check']\n",
      "attr after great continued\n",
      "attr b4 ['awesome', 'fast', 'really']\n",
      "attr after awesome fast\n",
      "attr b4 ['nice', 'go', 'great']\n",
      "attr after nice go\n",
      "attr b4 ['okay', 'prices', 'great']\n",
      "attr after okay prices\n",
      "attr b4 ['simple', 'does', 'truly']\n",
      "attr after simple does\n",
      "attr b4 ['its', 'good', 'value']\n",
      "attr after its good\n",
      "attr b4 ['nice', 'good', 'great']\n",
      "attr after nice good\n",
      "attr b4 ['good', 'food', 'great']\n",
      "attr after good food\n",
      "attr b4 ['tonight', 'ordered', 'good']\n",
      "attr after tonight ordered\n",
      "attr b4 ['gentle', 'always', 'kind']\n",
      "attr after gentle always\n",
      "attr b4 ['great', 'top', 'excellent']\n",
      "attr after great top\n",
      "attr b4 ['like', 'actually', 'purchasing']\n",
      "attr after like actually\n",
      "attr b4 ['definitely', 'home', 'eat']\n",
      "attr after definitely home\n",
      "attr b4 ['huge', 'fresh', 'good']\n",
      "attr after huge fresh\n",
      "attr b4 ['noisy', 'fresh', 'makes']\n",
      "attr after noisy fresh\n",
      "attr b4 ['took', 'very', 'well']\n",
      "attr after took very\n",
      "attr b4 ['always', 'great', 'team']\n",
      "attr after always great\n",
      "attr b4 ['best', 'part', 'sweet']\n",
      "attr after best part\n",
      "attr b4 ['place', 'must', \"'re\", 'bride']\n",
      "attr after place must\n",
      "attr b4 ['traditional', 'tastes', 'great']\n",
      "attr after traditional tastes\n",
      "attr b4 ['environment', 'cozy', 'friendly']\n",
      "attr after environment cozy\n",
      "attr b4 ['absolutely', 'hands', 'best']\n",
      "attr after absolutely hands\n",
      "attr b4 ['looks', 'gorgeous', 'happy']\n",
      "attr after looks gorgeous\n",
      "attr b4 ['town', 'first', 'place']\n",
      "attr after town first\n",
      "attr b4 ['wonderful', 'wonderful', 'excellent']\n",
      "attr after wonderful wonderful\n",
      "attr b4 ['person', 'enjoyed', 'praise']\n",
      "attr after person enjoyed\n",
      "attr b4 ['thorough', 'reasonably', 'answer']\n",
      "attr after thorough reasonably\n",
      "attr b4 ['totally', 'next', 'town']\n",
      "attr after totally next\n",
      "attr b4 [\"'re\", 'thing', 'stop', 'check']\n",
      "attr after 're thing\n",
      "attr b4 ['enjoy', 'here', 'slices']\n",
      "attr after enjoy here\n",
      "attr b4 ['super', 'friendly', 'top']\n",
      "attr after super friendly\n",
      "attr b4 ['super', 'better', 'chain']\n",
      "attr after super better\n",
      "attr b4 ['very', 'atmosphere', 'vintage']\n",
      "attr after very atmosphere\n",
      "attr b4 [\"'ve\", 'here', 'great']\n",
      "attr after 've here\n",
      "attr b4 ['good', 'vision', 'improved']\n",
      "attr after good vision\n",
      "attr b4 ['such', 'cool', 'swanky']\n",
      "attr after such cool\n",
      "attr b4 ['recommend', 'imports', 'auto']\n",
      "attr after recommend imports\n",
      "attr b4 ['girls', 'attractive', 'friendly']\n",
      "attr after girls attractive\n",
      "attr b4 ['took', 'home', 'delicious']\n",
      "attr after took home\n",
      "attr b4 ['eating', 'kings', 'best']\n",
      "attr after eating kings\n",
      "attr b4 ['great', 'great', 'can']\n",
      "attr after great great\n",
      "attr b4 [\"'ll\", 'definitely', 'here']\n",
      "attr after 'll definitely\n",
      "attr b4 ['extra', 'nice', 'good']\n",
      "attr after extra nice\n",
      "attr b4 ['food', 'go', 'here']\n",
      "attr after food go\n",
      "attr b4 ['hot', 'perfectly', 'delicious']\n",
      "attr after hot perfectly\n",
      "attr b4 ['travel', 'know', 'food']\n",
      "attr after travel know\n",
      "attr b4 ['enjoy', 'freshest', 'food']\n",
      "attr after enjoy freshest\n",
      "attr b4 ['owned', 'absolutely', 'amazing']\n",
      "attr after owned absolutely\n",
      "attr b4 ['...', 'very', 'good']\n",
      "attr after ... very\n",
      "attr b4 ['just', 'best', 'experiences', \"'ve\"]\n",
      "attr after just best\n",
      "attr b4 ['clean', 'well', 'reasonably']\n",
      "attr after clean well\n",
      "attr b4 ['remember', 'very', 'nice']\n",
      "attr after remember very\n",
      "attr b4 ['found', 'apartment', 'pretty']\n",
      "attr after found apartment\n",
      "attr b4 ['very', 'helpful', 'informative']\n",
      "attr after very helpful\n",
      "attr b4 ['located', 'great', 'really']\n",
      "attr after located great\n",
      "attr b4 ['super', 'friendly', 'amazing']\n",
      "attr after super friendly\n",
      "attr b4 ['great', 'very', 'friendly']\n",
      "attr after great very\n",
      "attr b4 ['great', 'authentic', 'vibe']\n",
      "attr after great authentic\n",
      "attr b4 ['new', 'new', 'flavors']\n",
      "attr after new new\n",
      "attr b4 ['family', 'friends', 'going']\n",
      "attr after family friends\n",
      "attr b4 [\"'ve\", 'added', 'new', 'items']\n",
      "attr after 've added\n",
      "attr b4 ['great', 'games', 'lively']\n",
      "attr after great games\n",
      "attr b4 ['best', 'dishes', \"'ve\", 'reasonable']\n",
      "attr after best dishes\n",
      "attr b4 ['good', 'bites', 'must']\n",
      "attr after good bites\n",
      "attr b4 ['goes', 'ranks', 'best', \"'ve\"]\n",
      "attr after goes ranks\n",
      "attr b4 ['so', 'delicious', \"'ve\", 'never']\n",
      "attr after so delicious\n",
      "attr b4 ['helped', 'very', 'friendly']\n",
      "attr after helped very\n",
      "attr b4 ['great', 'delicious', 'value']\n",
      "attr after great delicious\n",
      "attr b4 ['fair', 'fast', 'wonderful']\n",
      "attr after fair fast\n",
      "attr b4 ['right', 'friendly', 'happy']\n",
      "attr after right friendly\n",
      "attr b4 ['chose', 'great', 'incredible']\n",
      "attr after chose great\n",
      "attr b4 ['cute', 'east', 'great']\n",
      "attr after cute east\n",
      "attr b4 ['place', 'brought', 'nostalgia']\n",
      "attr after place brought\n",
      "attr b4 ['fun', 'catch', 'catch']\n",
      "attr after fun catch\n",
      "attr b4 ['great', 'spot', 'throw']\n",
      "attr after great spot\n",
      "attr b4 ['took', 'recommendation', 'super']\n",
      "attr after took recommendation\n",
      "attr b4 ['happy', 'crowd', 'fun']\n",
      "attr after happy crowd\n",
      "attr b4 ['great', 'experience', 'finish']\n",
      "attr after great experience\n",
      "attr b4 ['satisfying', 'flavor', 'well']\n",
      "attr after satisfying flavor\n",
      "attr b4 ['cool', 'place', 'lots']\n",
      "attr after cool place\n",
      "attr b4 ['super', 'friendly', 'amazingly']\n",
      "attr after super friendly\n",
      "attr b4 ['dr.', 'kind', 'gentle']\n",
      "attr after dr. kind\n",
      "attr b4 ['box', 'such', 'huge']\n",
      "attr after box such\n",
      "attr b4 ['hot', 'wonderful', 'amazing']\n",
      "attr after hot wonderful\n",
      "attr b4 ['got', 'screwed', 'made']\n",
      "attr after got screwed\n",
      "attr b4 ['can', 'honestly', 'az']\n",
      "attr after can honestly\n",
      "attr b4 ['recommend', 'wonderfully', 'talented']\n",
      "attr after recommend wonderfully\n",
      "attr b4 ['fantastic', 'location', 'm']\n",
      "attr after fantastic location\n",
      "attr b4 ['food', 'fresh', 'delicious']\n",
      "attr after food fresh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_file_v1(output_0_content_org, ref_out_path_0, True)\n",
    "process_file_v1(output_1_content_org, ref_out_path_1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path) as fp:\n",
    "        data = fp.read().splitlines()\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cleantransfer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1262644d422a82105623d802af89e6e9ed007275a479308d900e7081e9b63df8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
